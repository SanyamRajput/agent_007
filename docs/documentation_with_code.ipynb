{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "notebook_intro",
   "metadata": {},
   "source": [
    "# LangGraph Chatbot with Ollama\n",
    "\n",
    "## Prerequisites\n",
    "- Install required packages: `pip install langgraph langchain-community langchain-core`\n",
    "- Install and run Ollama locally\n",
    "- Pull the Gemma model: `ollama pull gemma:2b`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from typing import TypedDict, Annotated, Sequence\n",
    "from operator import add\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agent_state",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[HumanMessage | AIMessage], add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model_setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_model = ChatOllama(model=\"gemma:2b\", temperature=0.7)\n",
    "\n",
    "sys_prompt = SystemMessage(\n",
    "    content=\"You are Agent 007, a helpful and sophisticated AI assistant. \"\n",
    "            \"Answer questions clearly, professionally, and with a touch of wit when appropriate.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "llm_node",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_node(state: AgentState) -> AgentState:\n",
    "    messages = [sys_prompt] + list(state[\"messages\"])\n",
    "    response = llm_model.invoke(messages)\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create_graph",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_agent():\n",
    "    graph = StateGraph(AgentState)\n",
    "    graph.add_node(\"llm_model\", llm_node)\n",
    "    graph.set_entry_point(\"llm_model\")\n",
    "    graph.add_edge(\"llm_model\", END)\n",
    "    return graph.compile()\n",
    "\n",
    "bot = create_agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ask_bot",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_bot(question: str, conversation_history=None):\n",
    "    if conversation_history is None:\n",
    "        conversation_history = []\n",
    "    \n",
    "    user_msg = HumanMessage(content=question)\n",
    "    messages = conversation_history + [user_msg]\n",
    "    \n",
    "    result = bot.invoke({\"messages\": messages})\n",
    "    return result[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interactive_chat",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_interactive_chat():\n",
    "    print(\"ü§ñ Agent 007 Interactive Chat\")\n",
    "    print(\"Type your messages below. Type 'exit', 'bye', or 'quit' to end the conversation.\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    history = []\n",
    "    turn_count = 0\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            user_input = input(f\"\\n[Turn {turn_count + 1}] üë§ You: \").strip()\n",
    "            \n",
    "            if user_input.lower() in [\"exit\", \"bye\", \"quit\", \"stop\"]:\n",
    "                print(\"\\nü§ñ Agent 007: Until we meet again. Stay safe out there! üï¥Ô∏è\")\n",
    "                break\n",
    "            \n",
    "            if not user_input:\n",
    "                print(\"Please enter a message or type 'exit' to quit.\")\n",
    "                continue\n",
    "\n",
    "            user_msg = HumanMessage(content=user_input)\n",
    "            history.append(user_msg)\n",
    "\n",
    "            print(\"ü§î Agent 007 is thinking...\")\n",
    "            result = bot.invoke({\"messages\": history})\n",
    "            ai_msg = result[\"messages\"][-1]\n",
    "            \n",
    "            print(f\"\\nü§ñ Agent 007: {ai_msg.content}\")\n",
    "\n",
    "            history.append(ai_msg)\n",
    "            turn_count += 1\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n\\nü§ñ Agent 007: Mission interrupted. Farewell! üï¥Ô∏è\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error: {e}\")\n",
    "            print(\"Please try again or type 'exit' to quit.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utilities",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_conversation(history):\n",
    "    if not history:\n",
    "        print(\"No conversation history to analyze.\")\n",
    "        return\n",
    "    \n",
    "    human_messages = [msg for msg in history if isinstance(msg, HumanMessage)]\n",
    "    ai_messages = [msg for msg in history if isinstance(msg, AIMessage)]\n",
    "    \n",
    "    print(\"üìä Conversation Analysis\")\n",
    "    print(\"=\" * 25)\n",
    "    print(f\"Total messages: {len(history)}\")\n",
    "    print(f\"Human messages: {len(human_messages)}\")\n",
    "    print(f\"AI messages: {len(ai_messages)}\")\n",
    "    \n",
    "    if human_messages:\n",
    "        avg_human_length = sum(len(msg.content) for msg in human_messages) / len(human_messages)\n",
    "        print(f\"Average human message length: {avg_human_length:.1f} characters\")\n",
    "    \n",
    "    if ai_messages:\n",
    "        avg_ai_length = sum(len(msg.content) for msg in ai_messages) / len(ai_messages)\n",
    "        print(f\"Average AI message length: {avg_ai_length:.1f} characters\")\n",
    "\n",
    "def save_conversation(history, filename=\"conversation.json\"):\n",
    "    conversation_data = []\n",
    "    \n",
    "    for msg in history:\n",
    "        msg_data = {\n",
    "            \"type\": \"human\" if isinstance(msg, HumanMessage) else \"ai\",\n",
    "            \"content\": msg.content,\n",
    "            \"timestamp\": time.time()\n",
    "        }\n",
    "        conversation_data.append(msg_data)\n",
    "    \n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(conversation_data, f, indent=2)\n",
    "    \n",
    "    print(f\"üíæ Conversation saved to {filename}\")\n",
    "\n",
    "def quick_chat(questions_list):\n",
    "    history = []\n",
    "    \n",
    "    for i, question in enumerate(questions_list, 1):\n",
    "        print(f\"\\nüî∏ Question {i}: {question}\")\n",
    "        \n",
    "        user_msg = HumanMessage(content=question)\n",
    "        history.append(user_msg)\n",
    "        \n",
    "        result = bot.invoke({\"messages\": history})\n",
    "        ai_response = result[\"messages\"][-1]\n",
    "        \n",
    "        print(f\"ü§ñ Response: {ai_response.content}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        history.append(ai_response)\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "start_here",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage examples:\n",
    "# ask_bot(\"Your question here\")\n",
    "# run_interactive_chat()\n",
    "# quick_chat([\"question1\", \"question2\", \"question3\"])\n",
    "# analyze_conversation(history)\n",
    "# save_conversation(history, \"filename.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
